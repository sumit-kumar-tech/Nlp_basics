{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fa349e1-15ae-44fa-8296-c33c6bb17bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97196e19-386c-449c-85c2-b4c995d2d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf18814d-d569-4c69-832c-bfa841c60419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90aed1b1-9b83-48e2-8c31-3ee4fcd6e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0665611b-2678-42e6-8f31-92b0d84b78c2",
   "metadata": {},
   "source": [
    "# 1. Converting into lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32196a9b-7276-4a65-8f6c-1f891278c711",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"basically there's a family where a little boy (jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />this movie is slower than a soap opera... and suddenly, jake decides to become rambo and kill the zombie.<br /><br />ok, first of all when you're going to make a film you must decide if its a thriller or a drama! as a drama the movie is watchable. parents are divorcing & arguing like in real life. and then we have jake with his closet which totally ruins all the film! i expected to see a boogeyman similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. as for the shots with jake: just ignore them.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a15730cd-2c35-4be1-9c0f-dda3edbcd4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review']=df['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11e27e28-a12f-48da-aea6-0f6802d24721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098e4cdc-da45-4215-b94a-66475e27c535",
   "metadata": {},
   "source": [
    "# 2. Removing Html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc746e3-cae2-4204-b65f-a96fa1bf5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4eeed7f3-5fbb-4db8-baa7-a76c6f8dd1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3aa09ee-023b-47ef-b2f2-34332cdc2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(df['review'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5281fa6-a415-4d50-ac6e-2eff1ea1a01e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a wonderful little production. <br /><br />the filming technique is very unassuming- very old-time-bbc fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />the actors are extremely well chosen- michael sheen not only \"has got all the polari\" but he has all the voices down pat too! you can truly see the seamless editing guided by the references to williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. a masterful production about one of the great master\\'s of comedy and his life. <br /><br />the realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. it plays on our knowledge and our senses, particularly with the scenes concerning orton and halliwell and the sets (particularly of their flat with halliwell\\'s murals decorating every surface) are terribly well done.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50839de5-bdf4-4e86-95fb-c49a59811e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc85fa7-f212-4fff-8317-841acb6fe9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bf65b5-c5a9-4864-bc13-8f5b12f06b05",
   "metadata": {},
   "source": [
    "# 3. Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35ee9ed7-e410-43df-9c93-68f396bbd263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\s+|www\\.\\s+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e6cbf03-aa3d-431d-874b-f9feed160a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "992437a0-518a-4882-808d-bc402c82ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0339128-16f9-480e-844a-c00c947ff966",
   "metadata": {},
   "source": [
    "# 4. Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3583f4ef-d8ad-46ba-9dd3-aa9b705cb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b81377c-7bbe-4f4a-b986-07aa8bf3c994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c4bf8df-3c77-4512-bba9-183bcbe1e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0612e743-7d41-44ce-aff9-b1a292d471f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for i in exclude:\n",
    "        text = text.replace(i,'')\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b96f941f-0f60-464d-a23d-0999d4f07686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5132288932800293\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df['review']=df['review'].apply(remove_punc)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a02dabe4-86ab-4f01-ace8-936bf70a6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when working with large dataset \n",
    "def remove_punc1(text):\n",
    "    return text.translate(str.maketrans('','',exclude)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb3aee46-265f-4350-9316-df91b94a4d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8607892990112305\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df['review'].apply(remove_punc1)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebaad8a-e1c1-4dd5-b05e-d790fed20f4b",
   "metadata": {},
   "source": [
    "# 5. Chat word treatement like ASAP, GN, FYI etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f92244aa-70d1-4dca-962f-80c0c29262e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laughing my a** off\n",
    "LOL=Laughing out loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "QPSA?=Que Pasa?\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "TFW=That feeling when. TFW internet slang often goes in a caption to an image.\n",
    "MFW=My face when\n",
    "MRW=My reaction when\n",
    "IFYP=I feel your pain\n",
    "TNTL=Trying not to laugh\n",
    "JK=Just kidding\n",
    "IDC=I don't care\n",
    "ILY=I love you\n",
    "IMU=I miss you\n",
    "ADIH=Another day in hell\n",
    "ZZZ=Sleeping, bored, tired\n",
    "WYWH=Wish you were here\n",
    "TIME=Tears in my eyes\n",
    "BAE=Before anyone else\n",
    "FIMH=Forever in my heart\n",
    "BSAAW=Big smile and a wink\n",
    "BWL=Bursting with laughter\n",
    "BFF=Best friends forever\n",
    "CSL=Can't stop laughing\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d28cf6a-e79b-4910-a294-62f19301912c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"AFAIK\": \"As Far As I Know\",\n",
      "    \"AFK\": \"Away From Keyboard\",\n",
      "    \"ASAP\": \"As Soon As Possible\",\n",
      "    \"ATK\": \"At The Keyboard\",\n",
      "    \"ATM\": \"At The Moment\",\n",
      "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
      "    \"BAK\": \"Back At Keyboard\",\n",
      "    \"BBL\": \"Be Back Later\",\n",
      "    \"BBS\": \"Be Back Soon\",\n",
      "    \"BFN\": \"Bye For Now\",\n",
      "    \"B4N\": \"Bye For Now\",\n",
      "    \"BRB\": \"Be Right Back\",\n",
      "    \"BRT\": \"Be Right There\",\n",
      "    \"BTW\": \"By The Way\",\n",
      "    \"B4\": \"Before\",\n",
      "    \"CU\": \"See You\",\n",
      "    \"CUL8R\": \"See You Later\",\n",
      "    \"CYA\": \"See You\",\n",
      "    \"FAQ\": \"Frequently Asked Questions\",\n",
      "    \"FC\": \"Fingers Crossed\",\n",
      "    \"FWIW\": \"For What It's Worth\",\n",
      "    \"FYI\": \"For Your Information\",\n",
      "    \"GAL\": \"Get A Life\",\n",
      "    \"GG\": \"Good Game\",\n",
      "    \"GN\": \"Good Night\",\n",
      "    \"GMTA\": \"Great Minds Think Alike\",\n",
      "    \"GR8\": \"Great!\",\n",
      "    \"G9\": \"Genius\",\n",
      "    \"IC\": \"I See\",\n",
      "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
      "    \"ILU\": \"I Love You\",\n",
      "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
      "    \"IMO\": \"In My Opinion\",\n",
      "    \"IOW\": \"In Other Words\",\n",
      "    \"IRL\": \"In Real Life\",\n",
      "    \"KISS\": \"Keep It Simple, Stupid\",\n",
      "    \"LDR\": \"Long Distance Relationship\",\n",
      "    \"LMAO\": \"Laughing my a** off\",\n",
      "    \"LOL\": \"Laughing out loud\",\n",
      "    \"LTNS\": \"Long Time No See\",\n",
      "    \"L8R\": \"Later\",\n",
      "    \"MTE\": \"My Thoughts Exactly\",\n",
      "    \"M8\": \"Mate\",\n",
      "    \"NRN\": \"No Reply Necessary\",\n",
      "    \"OIC\": \"Oh I See\",\n",
      "    \"PITA\": \"Pain In The A..\",\n",
      "    \"PRT\": \"Party\",\n",
      "    \"PRW\": \"Parents Are Watching\",\n",
      "    \"QPSA?\": \"Que Pasa?\",\n",
      "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
      "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
      "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
      "    \"SK8\": \"Skate\",\n",
      "    \"STATS\": \"Your sex and age\",\n",
      "    \"ASL\": \"Age, Sex, Location\",\n",
      "    \"THX\": \"Thank You\",\n",
      "    \"TTFN\": \"Ta-Ta For Now!\",\n",
      "    \"TTYL\": \"Talk To You Later\",\n",
      "    \"U\": \"You\",\n",
      "    \"U2\": \"You Too\",\n",
      "    \"U4E\": \"Yours For Ever\",\n",
      "    \"WB\": \"Welcome Back\",\n",
      "    \"WTF\": \"What The F...\",\n",
      "    \"WTG\": \"Way To Go!\",\n",
      "    \"WUF\": \"Where Are You From?\",\n",
      "    \"W8\": \"Wait...\",\n",
      "    \"7K\": \"Sick:-D Laugher\",\n",
      "    \"TFW\": \"That feeling when. TFW internet slang often goes in a caption to an image.\",\n",
      "    \"MFW\": \"My face when\",\n",
      "    \"MRW\": \"My reaction when\",\n",
      "    \"IFYP\": \"I feel your pain\",\n",
      "    \"TNTL\": \"Trying not to laugh\",\n",
      "    \"JK\": \"Just kidding\",\n",
      "    \"IDC\": \"I don't care\",\n",
      "    \"ILY\": \"I love you\",\n",
      "    \"IMU\": \"I miss you\",\n",
      "    \"ADIH\": \"Another day in hell\",\n",
      "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
      "    \"WYWH\": \"Wish you were here\",\n",
      "    \"TIME\": \"Tears in my eyes\",\n",
      "    \"BAE\": \"Before anyone else\",\n",
      "    \"FIMH\": \"Forever in my heart\",\n",
      "    \"BSAAW\": \"Big smile and a wink\",\n",
      "    \"BWL\": \"Bursting with laughter\",\n",
      "    \"BFF\": \"Best friends forever\",\n",
      "    \"CSL\": \"Can't stop laughing\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def text_to_json(text):\n",
    "    # Split the input text by newlines to process each line\n",
    "    lines = text.strip().split('\\n')\n",
    "    # Create a dictionary to store the abbreviations and their meanings\n",
    "    result = {}\n",
    "    \n",
    "    # Process each line by splitting it at the '=' symbol\n",
    "    for line in lines:\n",
    "        key, value = line.split('=', 1)\n",
    "        result[key.strip()] = value.strip()\n",
    "    \n",
    "    # Convert the dictionary to a JSON-formatted string\n",
    "    return json.dumps(result, indent=4)\n",
    "\n",
    "\n",
    "json_output = text_to_json(text)\n",
    "print(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acab7910-701c-4949-9e6b-38545e32d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output={\n",
    "    \"AFAIK\": \"As Far As I Know\",\n",
    "    \"AFK\": \"Away From Keyboard\",\n",
    "    \"ASAP\": \"As Soon As Possible\",\n",
    "    \"ATK\": \"At The Keyboard\",\n",
    "    \"ATM\": \"At The Moment\",\n",
    "    \"A3\": \"Anytime, Anywhere, Anyplace\",\n",
    "    \"BAK\": \"Back At Keyboard\",\n",
    "    \"BBL\": \"Be Back Later\",\n",
    "    \"BBS\": \"Be Back Soon\",\n",
    "    \"BFN\": \"Bye For Now\",\n",
    "    \"B4N\": \"Bye For Now\",\n",
    "    \"BRB\": \"Be Right Back\",\n",
    "    \"BRT\": \"Be Right There\",\n",
    "    \"BTW\": \"By The Way\",\n",
    "    \"B4\": \"Before\",\n",
    "    \"CU\": \"See You\",\n",
    "    \"CUL8R\": \"See You Later\",\n",
    "    \"CYA\": \"See You\",\n",
    "    \"FAQ\": \"Frequently Asked Questions\",\n",
    "    \"FC\": \"Fingers Crossed\",\n",
    "    \"FWIW\": \"For What It's Worth\",\n",
    "    \"FYI\": \"For Your Information\",\n",
    "    \"GAL\": \"Get A Life\",\n",
    "    \"GG\": \"Good Game\",\n",
    "    \"GN\": \"Good Night\",\n",
    "    \"GMTA\": \"Great Minds Think Alike\",\n",
    "    \"GR8\": \"Great!\",\n",
    "    \"G9\": \"Genius\",\n",
    "    \"IC\": \"I See\",\n",
    "    \"ICQ\": \"I Seek you (also a chat program)\",\n",
    "    \"ILU\": \"I Love You\",\n",
    "    \"IMHO\": \"In My Honest/Humble Opinion\",\n",
    "    \"IMO\": \"In My Opinion\",\n",
    "    \"IOW\": \"In Other Words\",\n",
    "    \"IRL\": \"In Real Life\",\n",
    "    \"KISS\": \"Keep It Simple, Stupid\",\n",
    "    \"LDR\": \"Long Distance Relationship\",\n",
    "    \"LMAO\": \"Laughing my a** off\",\n",
    "    \"LOL\": \"Laughing out loud\",\n",
    "    \"LTNS\": \"Long Time No See\",\n",
    "    \"L8R\": \"Later\",\n",
    "    \"MTE\": \"My Thoughts Exactly\",\n",
    "    \"M8\": \"Mate\",\n",
    "    \"NRN\": \"No Reply Necessary\",\n",
    "    \"OIC\": \"Oh I See\",\n",
    "    \"PITA\": \"Pain In The A..\",\n",
    "    \"PRT\": \"Party\",\n",
    "    \"PRW\": \"Parents Are Watching\",\n",
    "    \"QPSA?\": \"Que Pasa?\",\n",
    "    \"ROFL\": \"Rolling On The Floor Laughing\",\n",
    "    \"ROFLOL\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "    \"ROTFLMAO\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "    \"SK8\": \"Skate\",\n",
    "    \"STATS\": \"Your sex and age\",\n",
    "    \"ASL\": \"Age, Sex, Location\",\n",
    "    \"THX\": \"Thank You\",\n",
    "    \"TTFN\": \"Ta-Ta For Now!\",\n",
    "    \"TTYL\": \"Talk To You Later\",\n",
    "    \"U\": \"You\",\n",
    "    \"U2\": \"You Too\",\n",
    "    \"U4E\": \"Yours For Ever\",\n",
    "    \"WB\": \"Welcome Back\",\n",
    "    \"WTF\": \"What The F...\",\n",
    "    \"WTG\": \"Way To Go!\",\n",
    "    \"WUF\": \"Where Are You From?\",\n",
    "    \"W8\": \"Wait...\",\n",
    "    \"7K\": \"Sick:-D Laugher\",\n",
    "    \"TFW\": \"That feeling when. TFW internet slang often goes in a caption to an image.\",\n",
    "    \"MFW\": \"My face when\",\n",
    "    \"MRW\": \"My reaction when\",\n",
    "    \"IFYP\": \"I feel your pain\",\n",
    "    \"TNTL\": \"Trying not to laugh\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"IDC\": \"I don't care\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"IMU\": \"I miss you\",\n",
    "    \"ADIH\": \"Another day in hell\",\n",
    "    \"ZZZ\": \"Sleeping, bored, tired\",\n",
    "    \"WYWH\": \"Wish you were here\",\n",
    "    \"TIME\": \"Tears in my eyes\",\n",
    "    \"BAE\": \"Before anyone else\",\n",
    "    \"FIMH\": \"Forever in my heart\",\n",
    "    \"BSAAW\": \"Big smile and a wink\",\n",
    "    \"BWL\": \"Bursting with laughter\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"CSL\": \"Can't stop laughing\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94b54630-ce15-461d-8ff3-c54e2e25a0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As Far As I Know you are Genius\n"
     ]
    }
   ],
   "source": [
    "def chat_conv(text):\n",
    "    new_text = []\n",
    "    for i in text.split():\n",
    "        if i.upper() in json_output:\n",
    "            new_text.append(json_output[i.upper()])\n",
    "        else:\n",
    "            new_text.append(i)  # This was incorrectly placed in your version\n",
    "\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Example usage\n",
    "print(chat_conv(\"AFAIK you are G9\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df90a76a-9c1e-486f-8459-f8398defd4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(chat_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31c2a8ef-684d-4a41-a3e6-0ce3a5599a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend Te...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the Tears in my eyes of...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend Te...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the Tears in my eyes of...  positive"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be494a41-3060-48b8-b0fd-8f361b12bc1e",
   "metadata": {},
   "source": [
    "# 6. Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0c1ec53-8662-4122-8682-ed1cc5fa6f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in ./envnlp/lib/python3.10/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in ./envnlp/lib/python3.10/site-packages (from textblob) (3.9.1)\n",
      "Requirement already satisfied: click in ./envnlp/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./envnlp/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./envnlp/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in ./envnlp/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24ed50c4-a710-43ac-a33e-f08c1a4d1e2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "418f6958-53cc-4d8e-a2dd-69e01bd44e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = \"ceertain condtions not moodiffied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0aa1c27a-bf70-4a79-91a4-bf96b83b4608",
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob = TextBlob(incorrect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "707f5627-479c-4fe9-a0c1-cbe7194cda99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'certain conditions not modified'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae7ac2-4f3a-4995-ba5b-d2030321307d",
   "metadata": {},
   "source": [
    "# 7. Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c19a1de-293a-4a99-bdca-f5ac6e6b0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c12c0fa-d19b-4999-9cbe-895711ef2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7197bfe8-bea1-411f-a239-04898304f565",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "482e080f-6677-4294-aa37-ae989aae6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def stop_words(text):\n",
    "    # Load English stopwords\n",
    "    stop_words_set = set(stopwords.words('english'))  # Using a set for faster lookups\n",
    "    new_text = [\n",
    "        word for word in text.split() if word.lower() not in stop_words_set\n",
    "    ]\n",
    "    return \" \".join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5437385-e2ec-4645-8032-115c330f0234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.365963935852051\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "df['review'] = df['review'].apply(stop_words)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93eed90f-c650-4d21-aff6-8e8b044a8c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend Tears eyes hot sum...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love Tears eyes money visually ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend Tears eyes hot sum...  positive\n",
       "3  basically theres family little boy jake thinks...  negative\n",
       "4  petter matteis love Tears eyes money visually ...  positive"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1849172-8470-47b9-95a8-98de7a65a073",
   "metadata": {},
   "source": [
    "# 8. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba6f8999-011a-4aaa-875e-9f8bc03a8b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sumitkumar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dcd65fb-0869-4819-bd9f-e5a0cb6fddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_tokenize(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d45ae8-d507-4c33-86bf-e1cc8b518f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one reviewers mentioned watching 1 oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scenes violence set right word go trust show faint hearted timid show pulls punches regards drugs sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focuses mainly emerald city experimental section prison cells glass fronts face inwards privacy high agenda em city home manyaryans muslims gangstas latinos christians italians irish moreso scuffles death stares dodgy dealings shady agreements never far awayi would say main appeal show due fact goes shows wouldnt dare forget pretty pictures painted mainstream audiences forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high levels graphic violence violence injustice crooked guards wholl sold nickel inmates wholl kill order get away well mannered middle class inmates turned prison bitches due lack street skills prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6968f8a8-b7b1-456f-8b80-366db41970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48c2eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0e534120",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50edf11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "reviewers\n",
      "mentioned\n",
      "watching\n",
      "1\n",
      "oz\n",
      "episode\n",
      "you\n",
      "ll\n",
      "hooked\n",
      "right\n",
      "exactly\n",
      "happened\n",
      "methe\n",
      "first\n",
      "thing\n",
      "struck\n",
      "oz\n",
      "brutality\n",
      "unflinching\n",
      "scenes\n",
      "violence\n",
      "set\n",
      "right\n",
      "word\n",
      "go\n",
      "trust\n",
      "show\n",
      "faint\n",
      "hearted\n",
      "timid\n",
      "show\n",
      "pulls\n",
      "punches\n",
      "regards\n",
      "drugs\n",
      "sex\n",
      "violence\n",
      "hardcore\n",
      "classic\n",
      "use\n",
      "wordit\n",
      "called\n",
      "oz\n",
      "nickname\n",
      "given\n",
      "oswald\n",
      "maximum\n",
      "security\n",
      "state\n",
      "penitentary\n",
      "focuses\n",
      "mainly\n",
      "emerald\n",
      "city\n",
      "experimental\n",
      "section\n",
      "prison\n",
      "cells\n",
      "glass\n",
      "fronts\n",
      "face\n",
      "inwards\n",
      "privacy\n",
      "high\n",
      "agenda\n",
      "em\n",
      "city\n",
      "home\n",
      "manyaryans\n",
      "muslims\n",
      "gangstas\n",
      "latinos\n",
      "christians\n",
      "italians\n",
      "irish\n",
      "moreso\n",
      "scuffles\n",
      "death\n",
      "stares\n",
      "dodgy\n",
      "dealings\n",
      "shady\n",
      "agreements\n",
      "never\n",
      "far\n",
      "awayi\n",
      "would\n",
      "say\n",
      "main\n",
      "appeal\n",
      "show\n",
      "due\n",
      "fact\n",
      "goes\n",
      "shows\n",
      "would\n",
      "nt\n",
      "dare\n",
      "forget\n",
      "pretty\n",
      "pictures\n",
      "painted\n",
      "mainstream\n",
      "audiences\n",
      "forget\n",
      "charm\n",
      "forget\n",
      "romanceoz\n",
      "does\n",
      "nt\n",
      "mess\n",
      "around\n",
      "first\n",
      "episode\n",
      "ever\n",
      "saw\n",
      "struck\n",
      "nasty\n",
      "surreal\n",
      "could\n",
      "nt\n",
      "say\n",
      "ready\n",
      "watched\n",
      "developed\n",
      "taste\n",
      "oz\n",
      "got\n",
      "accustomed\n",
      "high\n",
      "levels\n",
      "graphic\n",
      "violence\n",
      "violence\n",
      "injustice\n",
      "crooked\n",
      "guards\n",
      "who\n",
      "ll\n",
      "sold\n",
      "nickel\n",
      "inmates\n",
      "who\n",
      "ll\n",
      "kill\n",
      "order\n",
      "get\n",
      "away\n",
      "well\n",
      "mannered\n",
      "middle\n",
      "class\n",
      "inmates\n",
      "turned\n",
      "prison\n",
      "bitches\n",
      "due\n",
      "lack\n",
      "street\n",
      "skills\n",
      "prison\n",
      "experience\n",
      "watching\n",
      "oz\n",
      "may\n",
      "become\n",
      "comfortable\n",
      "uncomfortable\n",
      "viewingthats\n",
      "get\n",
      "touch\n",
      "darker\n",
      "side\n"
     ]
    }
   ],
   "source": [
    "for i in doc:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ebe4e",
   "metadata": {},
   "source": [
    "# 9. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c669f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information retrival system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bdf11be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f2b3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps= PorterStemmer()\n",
    "def stem_word(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3546b0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review mention watch 1 oz episod youll hook right exactli happen meth first thing struck oz brutal unflinch scene violenc set right word go trust show faint heart timid show pull punch regard drug sex violenc hardcor classic use wordit call oz nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home manyaryan muslim gangsta latino christian italian irish moreso scuffl death stare dodgi deal shadi agreement never far awayi would say main appeal show due fact goe show wouldnt dare forget pretti pictur paint mainstream audienc forget charm forget romanceoz doesnt mess around first episod ever saw struck nasti surreal couldnt say readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard wholl sold nickel inmat wholl kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort viewingthat get touch darker side'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_word(df['review'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c221356a",
   "metadata": {},
   "source": [
    "# 10. Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e8064d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b34c8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = WordNetLemmatizer()\n",
    "def lemma_word(text):\n",
    "    return \" \".join([lm.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3fdbca57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching 1 oz episode youll hooked right exactly happened methe first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use wordit called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home manyaryans muslim gangsta latino christian italian irish moreso scuffle death stare dodgy dealing shady agreement never far awayi would say main appeal show due fact go show wouldnt dare forget pretty picture painted mainstream audience forget charm forget romanceoz doesnt mess around first episode ever saw struck nasty surreal couldnt say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard wholl sold nickel inmate wholl kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewingthats get touch darker side'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_word(df['review'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5876e2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend Tears eyes hot sum...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love Tears eyes money visually ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend Tears eyes hot sum...  positive\n",
       "3  basically theres family little boy jake thinks...  negative\n",
       "4  petter matteis love Tears eyes money visually ...  positive"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a54a309",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/personal_project/NLP/envnlp/lib/python3.10/site-packages/pandas/core/strings/accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/personal_project/NLP/envnlp/lib/python3.10/site-packages/pandas/core/strings/accessor.py:2308\u001b[0m, in \u001b[0;36mStringMethods.get_dummies\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;124;03mReturn DataFrame of dummy/indicator variables for Series.\u001b[39;00m\n\u001b[1;32m   2273\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2304\u001b[0m \u001b[38;5;124;03m2  1  0  1\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2306\u001b[0m \u001b[38;5;66;03m# we need to cast to Series of strings as only that has all\u001b[39;00m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;66;03m# methods available for making the dummies...\u001b[39;00m\n\u001b[0;32m-> 2308\u001b[0m result, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_get_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43msep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(\n\u001b[1;32m   2310\u001b[0m     result,\n\u001b[1;32m   2311\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   2312\u001b[0m     expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2313\u001b[0m     returns_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   2314\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/personal_project/NLP/envnlp/lib/python3.10/site-packages/pandas/core/strings/object_array.py:396\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_get_dummies\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tags2):\n\u001b[1;32m    395\u001b[0m     pat \u001b[38;5;241m=\u001b[39m sep \u001b[38;5;241m+\u001b[39m t \u001b[38;5;241m+\u001b[39m sep\n\u001b[0;32m--> 396\u001b[0m     dummies[:, i] \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_isin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dummies, tags2\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/personal_project/NLP/envnlp/lib/python3.10/site-packages/pandas/core/strings/object_array.py:391\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_get_dummies.<locals>._isin\u001b[0;34m(test_elements, element)\u001b[0m\n\u001b[1;32m    387\u001b[0m tags2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(tags \u001b[38;5;241m-\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m    389\u001b[0m dummies \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mlen\u001b[39m(arr), \u001b[38;5;28mlen\u001b[39m(tags2)), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isin\u001b[39m(test_elements: \u001b[38;5;28mstr\u001b[39m, element: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m test_elements\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tags2):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_expanded = df['review'].str.get_dummies(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2383a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
